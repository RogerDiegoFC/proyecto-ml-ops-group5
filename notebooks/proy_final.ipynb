{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3602b2-202d-4f58-9f48-ec886e1f0d68",
   "metadata": {},
   "source": [
    "## Prueba Final: Machine Learning con Spark y Docker\n",
    "## Predicción de la Calidad del Vino con PySpark en un Entorno Dockerizado\n",
    "### ROGER DIEGO FLORES CONDORI\n",
    "### Parte 2: Desarrollo del Proyecto en JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667d2b4-50fd-4ec5-8950-b912def2c09d",
   "metadata": {},
   "source": [
    "### Dentro del notebook que creaste, sigue los siguientes pasos.\n",
    "---\n",
    "### Paso 1: Configuración e Inicio de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7fb867-6228-4be9-8776-71e7e77ee668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession disponible. Configuración:\n",
      "[('spark.app.id', 'local-1753051537974'), ('spark.driver.host', '11bdd832def2'), ('spark.executor.id', 'driver'), ('spark.app.name', 'TitanicML'), ('spark.driver.memory', '1g'), ('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.app.submitTime', '1753051534010'), ('spark.master', 'local[*]'), ('spark.driver.port', '35923'), ('spark.submit.pyFiles', ''), ('spark.app.startTime', '1753051534401'), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true'), ('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TitanicML\").getOrCreate()\n",
    "# La SparkSession ya está creada. Podemos verificar su configuración.\n",
    "print(\"SparkSession disponible. Configuración:\")\n",
    "print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04013b97-1c18-4017-9cf3-4c945e5e8dab",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 2: Carga y Exploración de Datos (ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6226547b-624c-4025-8871-7897b289a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset, indicando que tiene encabezado e infiriendo el esquema.\n",
    "df = spark.read.csv('/data/wine.csv', header=True, inferSchema=True, sep=';')\n",
    "print(\"Dataset cargado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecc4d14-71ba-4383-82cb-828014788306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema del DataFrame:\n",
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- total sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n",
      "\n",
      "Primeras 10 filas:\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8|      5|\n",
      "|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8|      5|\n",
      "|         11.2|            0.28|       0.56|           1.9|    0.075|               17.0|                60.0|  0.998|3.16|     0.58|    9.8|      6|\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "|          7.4|            0.66|        0.0|           1.8|    0.075|               13.0|                40.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "|          7.9|             0.6|       0.06|           1.6|    0.069|               15.0|                59.0| 0.9964| 3.3|     0.46|    9.4|      5|\n",
      "|          7.3|            0.65|        0.0|           1.2|    0.065|               15.0|                21.0| 0.9946|3.39|     0.47|   10.0|      7|\n",
      "|          7.8|            0.58|       0.02|           2.0|    0.073|                9.0|                18.0| 0.9968|3.36|     0.57|    9.5|      7|\n",
      "|          7.5|             0.5|       0.36|           6.1|    0.071|               17.0|               102.0| 0.9978|3.35|      0.8|   10.5|      5|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el esquema del DataFrame para entender los tipos de datos\n",
    "print(\"Esquema del DataFrame:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Mostrar las primeras 10 filas del DataFrame\n",
    "print(\"\\nPrimeras 10 filas:\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e684a1e2-7dba-47e7-880e-7f0ed28c59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros: 1599\n",
      "Cantidad de columnas: 12\n"
     ]
    }
   ],
   "source": [
    "num_filas = df.count()\n",
    "num_columnas = len(df.columns)\n",
    "\n",
    "print(f\"Cantidad de registros: {num_filas}\")\n",
    "print(f\"Cantidad de columnas: {num_columnas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c42b1cd-eb63-4510-9589-f6eb28f9e410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|     fixed acidity|   volatile acidity|        citric acid|    residual sugar|           chlorides|free sulfur dioxide|total sulfur dioxide|             density|                 pH|         sulphates|           alcohol|           quality|\n",
      "+-------+------------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|              1599|               1599|               1599|              1599|                1599|               1599|                1599|                1599|               1599|              1599|              1599|              1599|\n",
      "|   mean| 8.319637273295838| 0.5278205128205131| 0.2709756097560964|2.5388055034396517| 0.08746654158849257| 15.874921826141339|   46.46779237023139|  0.9967466791744831|  3.311113195747343|0.6581488430268921|10.422983114446502|5.6360225140712945|\n",
      "| stddev|1.7410963181276948|0.17905970415353525|0.19480113740531824|  1.40992805950728|0.047065302010090085|  10.46015696980971|   32.89532447829907|0.001887333953842...|0.15438646490354271|0.1695069795901101|1.0656675818473935|0.8075694397347051|\n",
      "|    min|               4.6|               0.12|                0.0|               0.9|               0.012|                1.0|                 6.0|             0.99007|               2.74|              0.33|               8.4|                 3|\n",
      "|    25%|               7.1|               0.39|               0.09|               1.9|                0.07|                7.0|                22.0|              0.9956|               3.21|              0.55|               9.5|                 5|\n",
      "|    50%|               7.9|               0.52|               0.26|               2.2|               0.079|               14.0|                38.0|             0.99675|               3.31|              0.62|              10.2|                 6|\n",
      "|    75%|               9.2|               0.64|               0.42|               2.6|                0.09|               21.0|                62.0|             0.99784|                3.4|              0.73|              11.1|                 6|\n",
      "|    max|              15.9|               1.58|                1.0|              15.5|               0.611|               72.0|               289.0|             1.00369|               4.01|               2.0|              14.9|                 8|\n",
      "+-------+------------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resumen estadístico \n",
    "df.summary().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c863522-16a9-4007-a068-76b401237722",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 3: Preparación de Datos y Feature Engineering\n",
    "#### Transformación de la variable objetivo: Crea una nueva columna label que sea 1.0 si quality es mayor que 5 (buena calidad) y 0.0 en caso contrario (calidad estándar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38feff4e-e4b6-45d4-b44b-fd01c7c1ebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|quality|label|\n",
      "+-------+-----+\n",
      "|      5|  0.0|\n",
      "|      5|  0.0|\n",
      "|      5|  0.0|\n",
      "|      6|  1.0|\n",
      "|      5|  0.0|\n",
      "|      5|  0.0|\n",
      "|      5|  0.0|\n",
      "|      7|  1.0|\n",
      "|      7|  1.0|\n",
      "|      5|  0.0|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  744|\n",
      "|  1.0|  855|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "\n",
    "df = df.withColumn(\n",
    "    'label',\n",
    "    expr(\"CASE WHEN quality > 5 THEN 1.0 ELSE 0.0 END\")\n",
    ")\n",
    "\n",
    "df.select('quality', 'label').show(10)\n",
    "df.groupBy('label').count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62982cb2-1b51-4aad-8066-eebf7780099a",
   "metadata": {},
   "source": [
    "#### División de Datos: Divide el dataset en entrenamiento (80%) y prueba (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2627c1e-d125-4a6d-b4d8-8d7d6d961080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 1324 registros\n",
      "Tamaño del conjunto de prueba: 275 registros\n"
     ]
    }
   ],
   "source": [
    "# Semilla para reproducibilidad\n",
    "seed = 42\n",
    "\n",
    "# División del dataset en entrenamiento y prueba (80% - 20%)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=seed)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {train_data.count()} registros\")\n",
    "print(f\"Tamaño del conjunto de prueba: {test_data.count()} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01660edc-0c4a-4ea9-a43b-6b4906f139bb",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 4: Entrenamiento de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbed7054-e8b0-40cc-b8fd-bbacc7388e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Definir las columnas predictoras\n",
    "caracteristicas = [c for c in df.columns if c not in ['quality', 'label']]\n",
    "\n",
    "# Crear el ensamblador de características\n",
    "ensamblador = VectorAssembler(inputCols=caracteristicas, outputCol=\"caracteristicas\")\n",
    "\n",
    "# Aplicar el ensamblador\n",
    "datos_entrenamiento = ensamblador.transform(train_data)\n",
    "datos_prueba = ensamblador.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a533cd-966c-46f5-a346-175197d985fd",
   "metadata": {},
   "source": [
    "#### 1. Regresión Logística (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2a821a-456b-44c3-9780-c20313cf0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento de Regresión Logística finalizado.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Crear y ajustar el modelo de regresión logística\n",
    "regresion_logistica = LogisticRegression(featuresCol=\"caracteristicas\", labelCol=\"label\")\n",
    "modelo_reg_log = regresion_logistica.fit(datos_entrenamiento)\n",
    "\n",
    "print(\"Entrenamiento de Regresión Logística finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd0945-1285-4c81-80d4-1ab0d7580ab6",
   "metadata": {},
   "source": [
    "#### 2. Árbol de Decisión (DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2bfc0e-c2e2-47ee-82c1-37d65ac17dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento de Árbol de Decisión completado.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Crear y ajustar el modelo de árbol de decisión\n",
    "arbol_decision = DecisionTreeClassifier(featuresCol=\"caracteristicas\", labelCol=\"label\")\n",
    "modelo_arbol = arbol_decision.fit(datos_entrenamiento)\n",
    "\n",
    "print(\"Entrenamiento de Árbol de Decisión completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881c3b7-2feb-42b9-900b-3fdf3881b08f",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 5: Evaluación de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b785f-9cd6-45f3-aa2a-8e61498cfcc1",
   "metadata": {},
   "source": [
    "#### Realiza predicciones sobre el conjunto de prueba para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a46a545-f0e6-48d0-99ea-144f57d9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en los datos de prueba\n",
    "resultados_reg_log = modelo_reg_log.transform(datos_prueba)\n",
    "resultados_arbol = modelo_arbol.transform(datos_prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9161fe-2d93-46d0-98d5-393e921be834",
   "metadata": {},
   "source": [
    "#### Usa BinaryClassificationEvaluator con la métrica Área Bajo la Curva ROC (AUC) para evaluar cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbe3983-90ca-428e-8032-a598aae48d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - Regresión Logística: 0.8350663129973478\n",
      "AUC - Árbol de Decisión: 0.702970822281167\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Crear evaluador\n",
    "evaluador = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Evaluación de Regresión Logística\n",
    "roc_reg_log = evaluador.evaluate(resultados_reg_log)\n",
    "print(f\"AUC - Regresión Logística: {roc_reg_log}\")\n",
    "\n",
    "# Evaluación de Árbol de Decisión\n",
    "roc_arbol = evaluador.evaluate(resultados_arbol)\n",
    "print(f\"AUC - Árbol de Decisión: {roc_arbol}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170db03-0431-454c-a23e-2b0b21a0bd3a",
   "metadata": {},
   "source": [
    "#### Imprime el AUC de cada modelo y concluye cuál tuvo el mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dafd6f-bd3d-4ed3-9f95-df9add5178c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Conclusión del experimento ---\n",
      "La Regresión Logística presentó un mejor desempeño en términos de AUC, lo que indica una mayor capacidad para discriminar entre clases.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Conclusión del experimento ---\")\n",
    "\n",
    "if roc_reg_log > roc_arbol:\n",
    "    print(\"La Regresión Logística presentó un mejor desempeño en términos de AUC, lo que indica una mayor capacidad para discriminar entre clases.\")\n",
    "elif roc_arbol > roc_reg_log:\n",
    "    print(\"El Árbol de Decisión obtuvo un mejor AUC, lo que sugiere un mejor rendimiento en esta tarea de clasificación.\")\n",
    "else:\n",
    "    print(\"Ambos modelos tuvieron el mismo AUC, por lo tanto su rendimiento es equivalente en este caso.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
